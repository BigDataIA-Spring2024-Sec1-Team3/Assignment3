{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean CSVs upload to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to create snowflake connection, internal staging, creating table, staging data and loading staged data to Snowflake database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('configuration.properties')\n",
    "\n",
    "user = config['SNOWFLAKE']['User']\n",
    "password = config['SNOWFLAKE']['Password']\n",
    "account = config['SNOWFLAKE']['Account']\n",
    "warehouse = config['SNOWFLAKE']['Warehouse']\n",
    "database = config['SNOWFLAKE']['Database']\n",
    "schema = config['SNOWFLAKE']['Schema']\n",
    "\n",
    "# Create a connection string\n",
    "connection_string = f'snowflake://{user}:{password}@{account}/' \\\n",
    "                        f'?warehouse={warehouse}&database={database}&schema={schema}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create stage\n",
    "def create_internal_stage_for_classes(engine, stage_name):\n",
    "    create_stage_query = f\"\"\"\n",
    "    CREATE OR REPLACE STAGE {stage_name};\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(create_stage_query))\n",
    "    \n",
    "    print(f\"Stage {stage_name} created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create table with specified table and column names\n",
    "def create_table_for_csv_files(engine, table_name, column_names):\n",
    "    create_table_query = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE {table_name} (\n",
    "        {column_names}\n",
    "    );\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(create_table_query))\n",
    "    \n",
    "    print(f\"Table {table_name} created successfully\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to put data into internal stage\n",
    "def put_data_into_stage(engine, csv_file_path, stage_name):\n",
    "    put_data_query = f\"\"\"\n",
    "    PUT file://{csv_file_path} @{stage_name};\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(put_data_query))\n",
    "    \n",
    "    print(f\"Data Loaded into {stage_name} successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create file format with given file format name and field delimeter\n",
    "def creating_file_format(engine, ff_name, field_delim):\n",
    "    create_ff_query = f\"\"\"\n",
    "    CREATE OR REPLACE FILE FORMAT {ff_name}\n",
    "    TYPE = 'CSV'\n",
    "    FIELD_DELIMITER = '{field_delim}'\n",
    "    SKIP_HEADER = 1\n",
    "    SKIP_BLANK_LINES = True\n",
    "    EMPTY_FIELD_AS_NULL = true\n",
    "    TRIM_SPACE = True;\n",
    "    \"\"\"\n",
    "    # print(create_ff_query)\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(create_ff_query))\n",
    "    \n",
    "    print(f\"File format {ff_name} created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load data from stage to table\n",
    "def load_data_from_stage_to_table(engine, table_name, stage_name, ff_name):\n",
    "    copy_into_query = f\"\"\"\n",
    "    COPY INTO {table_name} FROM @{stage_name} FILE_FORMAT = (FORMAT_NAME = {ff_name});\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(copy_into_query))\n",
    "    \n",
    "    print(f\"Data loaded from {stage_name} to {table_name} successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to upload data to Snowflake Database:  \n",
    "1. Create an engine for Snowflake connection  \n",
    "2. Create an internal stage in Snowflake  \n",
    "3. Create a table with reference to CSV structure  \n",
    "4. Put data into stage  \n",
    "5. Load data from stage to table using COPY INTO command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine created for snowflake sqlalchemy\n",
      "Stage url_class_stage created successfully\n",
      "Stage pdf_metadata_stage created successfully\n",
      "Stage pdf_content_stage created successfully\n",
      "Table URLDATA created successfully\n",
      "Table PDFMETADATA created successfully\n",
      "Table PDFCONTENTDATA created successfully\n",
      "File format url_data_ff created successfully\n",
      "File format pdf_data_ff created successfully\n",
      "Data Loaded into url_class_stage successfully\n",
      "Data Loaded into pdf_metadata_stage successfully\n",
      "Data Loaded into pdf_content_stage successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raisi\\AppData\\Local\\Temp\\ipykernel_15580\\1448471379.py:7: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  connection.execute(text(copy_into_query))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from url_class_stage to URLDATA successfully\n",
      "Data loaded from pdf_metadata_stage to PDFMETADATA successfully\n",
      "Data loaded from pdf_content_stage to PDFCONTENTDATA successfully\n"
     ]
    }
   ],
   "source": [
    "# Create an engine for Snowflake Connection\n",
    "engine = create_engine(connection_string)\n",
    "print(\"Engine created for snowflake sqlalchemy\")\n",
    "\n",
    "# declaring stage, file formats and table names\n",
    "url_stage_name = 'url_class_stage'\n",
    "pdf_metadata_stage_name = 'pdf_metadata_stage'\n",
    "pdf_content_stage_name = 'pdf_content_stage'\n",
    "\n",
    "url_ff = 'url_data_ff' \n",
    "pdf_data_ff = 'pdf_data_ff'\n",
    "\n",
    "url_table = 'URLDATA'\n",
    "pdf_metadata_table = 'PDFMETADATA'\n",
    "pdf_content_table = 'PDFCONTENTDATA'\n",
    "\n",
    "# Creating 3 stages for URLClass, PDF metadata and PDF content\n",
    "create_internal_stage_for_classes(engine, url_stage_name)\n",
    "create_internal_stage_for_classes(engine, pdf_metadata_stage_name)\n",
    "create_internal_stage_for_classes(engine, pdf_content_stage_name)\n",
    "\n",
    "# Create a table\n",
    "create_table_for_csv_files(engine, url_table, 'topic_name VARCHAR, year INT, level VARCHAR, introduction VARCHAR,learning_outcome VARCHAR, summary VARCHAR, summary_page_link VARCHAR, pdf_file_link VARCHAR')\n",
    "create_table_for_csv_files(engine, pdf_metadata_table, 'text VARCHAR, para INT, bboxes VARIANT, pages VARIANT, section_title VARCHAR, section_number VARCHAR, paper_title VARCHAR, file_path VARCHAR')\n",
    "create_table_for_csv_files(engine, pdf_content_table, 'title VARCHAR, topic_name VARCHAR, year INT, level VARCHAR, learning_outcome VARCHAR')\n",
    "\n",
    "# create file format\n",
    "creating_file_format(engine, url_ff, '\\\\t')\n",
    "creating_file_format(engine, pdf_data_ff, '|')\n",
    "\n",
    "# Stage the data\n",
    "put_data_into_stage(engine, 'data\\output\\clean_url_class.csv', url_stage_name)\n",
    "put_data_into_stage(engine, 'data\\output\\clean_pdf_metadata.csv', pdf_metadata_stage_name)\n",
    "put_data_into_stage(engine, 'data\\output\\clean_pdf_content.csv', pdf_content_stage_name)\n",
    "\n",
    "# Load data from stage to table \n",
    "load_data_from_stage_to_table(engine, url_table, url_stage_name, url_ff)\n",
    "load_data_from_stage_to_table(engine, pdf_metadata_table, pdf_metadata_stage_name, pdf_data_ff)\n",
    "load_data_from_stage_to_table(engine, pdf_content_table, pdf_content_stage_name, pdf_data_ff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
